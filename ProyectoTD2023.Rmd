---
title: "ProyectoTD2023"
author: "Jose Garcia Mora, Lucia Chulvi Deogracia, David Camarena Sánchez, Ruben Peña Sanchez"
date: "`r Sys.Date()`"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## INTRODUCCIÓN

Primero, el código define una lista de paquetes necesarios, los carga si están disponibles o los instala y carga si no lo están. Luego, define una función llamada "get_data" que toma una ruta de archivo como entrada y devuelve un data frame que contiene los datos de los diferentes archivos. La función primero lee los datos de la cabecera digital y el archivo digital y los almacena en variables separadas. Luego, los datos se almacenan en una lista con cada variable de datos en una posición separada en la lista. Se calculan algunas estadísticas de los datos, como la media de una variable. Luego, la lista se procesa para que cada variable tenga el mismo número de filas. A continuación, se convierte la lista en un data frame y se agrega una variable de tiempo al data frame. El data frame resultante tiene una fila para cada unidad de tiempo y contiene los datos de las diferentes variables. Finalmente, se usa la biblioteca "tidyverse" para procesar y visualizar los datos.

```{r eval=T, include=F}
# Especificamos las librerías necesarias en esta lista
packages = c("knitr", "ggplot2","tidyr","dplyr","readr", "tidyverse", "plotly")# use this function to check if each package is on the local machine
# if a package is installed, it will be loaded
# if any are not, the missing package(s) will be installed and loaded
package.check <- lapply(packages, FUN = function(x) {
  if (!require(x, character.only = TRUE)) {
    install.packages(x, dependencies = TRUE,repos='http://cran.rediris.es')
    library(x, character.only = TRUE)
  }
})
# verify they are loaded
search()
```

```{r}
library(tidyverse)
# La siguiente función nos permitirá obtener los datos de los diferentes ficheros , así como guardarlos en una lista. También calcularemos datos como la media, el número máximo, etc. Posteriormente hemos tenido en cuenta el fichero analógico. Además, también hemos tenido en cuenta el tipo de fichero a importar, ya que dependiendo del mismo se debe proceder con diferentes métodos.
get_data <- function(ruta){
###### cabecera digital ######
  ficheroCD <- paste0(ruta, "cabecera_FicheroDigital.DAT")
  cabecera_digital <- readBin(con = ficheroCD, what = "integer", n = 8, size = 1, signed = FALSE)
  
###### fichero digital ######
  ficheroB <- paste0(ruta, "ficheroDigital.DAT")
  datos_digitales <- readBin(con = ficheroB, what = "integer", n = 2000000, size = 1, signed = FALSE)
  
  # Almacenamiento de los datos de los diferentes ficheros:
  HR1 <- datos_digitales[seq(from = 1, to = length(datos_digitales), by = 9)]
  HR2 <- datos_digitales[seq(from = 2, to = length(datos_digitales), by = 9)]
  MHR <- datos_digitales[seq(from = 3, to = length(datos_digitales), by = 9)]
  TOCO <- datos_digitales[seq(from = 4, to = length(datos_digitales), by = 9)]
  MSpO2 <- datos_digitales[seq(from = 5, to = length(datos_digitales), by = 9)]
  VCP <- datos_digitales[seq(from = 6, to = length(datos_digitales), by = 9)]
  Psistolica <- datos_digitales[seq(from = 7, to = length(datos_digitales), by = 9)]
  Pdiastolica <- datos_digitales[seq(from = 8, to = length(datos_digitales), by = 9)]
  Pmedia <- datos_digitales[seq(from = 9, to = length(datos_digitales), by = 9)]
  
  mediaVCP <- mean(VCP) # cálculo de la media de la VCP
  
  # Almacenar las variables en una lista
  df_list <- list(HR1, HR2, MHR, TOCO, MSpO2, VCP, Psistolica, Pdiastolica, Pmedia)
  
  # Calcular el número máximo de filas
  max_filas <- max(sapply(df_list, length))
  
  # Recorrer cada vector en la lista
  for (i in 1:length(df_list)) {
    # Obtener el vector actual
    vector_actual <- df_list[[i]]
    # Calcular la mediana del vector
    mediana_actual <- median(vector_actual)
    
    # Comprobar si el vector necesita relleno
    if (length(vector_actual) < max_filas) {
      # Calcular el número de filas a rellenar
      filas_relleno <- max_filas - length(vector_actual)
      
      # Rellenar el vector con la mediana
      vector_relleno <- rep(mediana_actual, filas_relleno)
      
      # Concatenar el vector original y el vector de relleno
      df_list[[i]] <- c(vector_actual, vector_relleno)
    }
  }
  
  # Convertir la lista en un data frame
  datos_digitales <- as.data.frame(df_list)
  
  # Renombrar las columnas del data frame
  colnames(datos_digitales) <- c("HR1", "HR2", "MHR", "TOCO", "MSpO2", "VCP", "Psistolica", "Pdiastolica", "Pmedia")
  
  # Crea la variable tiempo #by = 0.025
  tiempo <- seq(0, length.out = nrow(datos_digitales), by = 0.22)
  # Selecciona las primeras 2604 filas de tiempo
  tiempo <- head(tiempo, nrow(datos_digitales))
  
  # Añade la variable tiempo al data frame
  datos_digitales <- datos_digitales %>%
    mutate(tiempo = tiempo)
  
  # tiempo de registro
  hora <- ((((length(datos_digitales) / 9) / 4) / 60) / 60)
  min <- ((hora - floor(hora)) * 60)
  seg <- ((min - floor(min))) * 60
  
  tiempo_digital <- cbind(hora, min, seg)
  
  
###### cabecera analogica ######
  ficheroCA <- paste0(ruta, 'cabecera_FicheroAnalogico.DAT')
  f2 <- file(ficheroCA, 'rb')
  Cabecera_A1 <- readBin(f2, "integer", n=7, size=1, signed=FALSE)
  Cabecera_A2 <- readBin(f2, "integer", n=3, size=2, signed=TRUE)
  close(f2)
  
###### fichero analógico ######
  fichero <- paste0(ruta, 'ficheroAnalogico.DAT')
  f2 <- file(fichero, 'rb')
  datos_analogicos <- readBin(f2, "integer", n=20000000, size=2, signed=TRUE)
  close(f2)
  
  Fm <- 1000
  tiempo_analogico <- seq(from = 0, to = (length(datos_analogicos)-1)/Fm, by = 1/Fm)
  
  # Crear el data.frame de los datos
  datos_analogicos <- data.frame(tiempo_analogico, datos_analogicos)
  
  # Tiempo de registro
  hora <- ((length(datos_analogicos)/Fm)/60)/60
  min <- ((hora - floor(hora)) * 60)
  seg <- ((min - floor(min)) * 60)
  
  tiempo_analogico <- cbind(hora, min, seg)
  
  dfs <- list(datos_digitales, tiempo_digital, datos_analogicos, tiempo_analogico)
  vectores <- list(cabecera_digital, Cabecera_A1, Cabecera_A2)
  return(list(dfs, vectores))
}
```

```{r}
ruta <- "data/1059xlxveei79_ECGf2/27_09_2022/14.42.29_III_ECGyEXTyRESTO/"
data <- get_data(ruta)

##Añadir variables para almacenar los datos de forma mas accesible##

#Datos del fichero digital y total de tiempo de señal digital:
datos_digitales <- as.data.frame(data[[1]][1])
tiempo_total_A <- as.data.frame(data[[1]][2])

# Observamos resumen de los datos:
summary(datos_digitales)
head(datos_digitales)
tail(datos_digitales)

mean(datos_digitales$tiempo)
mean(datos_digitales$HR1)
mean(datos_digitales$HR2)

median(datos_digitales$tiempo)
median(datos_digitales$HR1)
median(datos_digitales$HR2)

#Datos del fichero analogico y total de tiempo de señal analogica:
datos_analogicos <- as.data.frame(data[[1]][3])
tiempo_total_A <- as.data.frame(data[[1]][4])

# Observamos resumen de los datos:
summary(datos_analogicos)
head(datos_analogicos)
tail(datos_analogicos)

mean(datos_analogicos$tiempo_analogico)
mean(datos_analogicos$datos_analogicos)

median(datos_analogicos$tiempo_analogico)
median(datos_analogicos$datos_analogicos)

#Datos de las cabeceras:
cabecera_digital <- unlist(data[[2]][1])
cabecera_analogica1 <- unlist(data[[2]][2])
cabecera_analogica2 <- unlist(data[[2]][3])
```

```{r}
###### Gráfico fichero analógico ######

#Obtenemos los datos de los 10 últimos segundos de señal:
datos_analogicos10 <- subset(datos_analogicos, tiempo_analogico > max(tiempo_analogico)-10)

#Representamos los ultimos 10 segundos de la señal a través de un gráfico interactivo:
g <- ggplot(datos_analogicos10, aes(tiempo_analogico, datos_analogicos)) +
  geom_line(aes(col="red")) +
  labs(
    title = "Señal analógica",
    x = "Tiempo",
    y = "Señal"
  )
ggplotly(g)

# Si observamos los resultados podemos observar que la señal parece bastante estable, teniendo un intervalo de altos y bajos en forma de patrón.
```

```{r}
###### Grafico fichero digital ######
#Seleccionamos los datos con tiempo menor a 1300
#2603
datos_digitales300 <- subset(datos_digitales, tiempo <= 300)

#Adaptamos los datos para poder representarlos:
datos_digitales300 <- gather(datos_digitales300, key = "variable", value = "valor", -tiempo)

#Representamos los datos:
# Con esta gráfica se pretende la observación de diversas variables en un intervalo de tiempo determinado, de forma que a simple vista se pueda realizar un estudio de los resultados:
ggplot(datos_digitales300, aes(x = tiempo, y = valor, color = variable)) +
  geom_line() +
  facet_wrap(~ variable, scales = "free") +
  labs(
    x = "Tiempo",
    y = "Valor",
  )
```

```{r}
#A partir de los datos anteriormente conseguidos vamos a comparar las variables HR1 y HR2 y comprobar si tienen correlación entre sí.

#Escogemos  solamente las variables HR1 y HR2:
datosHR1HR2<- datos_digitales300[datos_digitales300$variable %in% c("HR1","HR2"),]

#Representamos la grafica con ambas Variables para ver si pueden tener correlacion entre si.

ggplot(datosHR1HR2, aes(x = tiempo, y =valor, color =variable))+geom_line(size=0.8)+labs(x="Tiempo",y="Valor")

#Para conseguir ver la correlacion que tienen los datos con la funcion cor() es imprescindible que los datos de los cuales queremos saber la correlacion esten en diferentes columnas por lo tanto utilizaremos la funcion pivot_wider

datosHR1HR2pw<-pivot_wider(data = datosHR1HR2,names_from = variable,values_from=valor)

#Vemos la correlacion que tienen entre si

cor(datosHR1HR2pw$HR1,datosHR1HR2pw$HR2)

#La correlacion es muy debil a pesar de que no lo parezca en la grafica, esto se debe a que en ambas variables encontramos datos anomalos. Eliminaremos estos datos,mirando la anterior grafica notamos que en ambas variables la mayoria de los datos se encuentran en el rango  [100,175],en cambio hay unos pocos valores que o bien son muy pequeños o son 0. Eliminaremos los datos que valgan menos de 50

datosNoAnomalosHR12<- datosHR1HR2pw[datosHR1HR2pw$HR1>=50 & datosHR1HR2pw$HR2>=50,]

#Vemos el rango comprobando que los datos tienen un rango similar
range(datosNoAnomalosHR12$HR1)
range(datosNoAnomalosHR12$HR2)

#Utilizaremos la funcion pivot_longer para ver de nuevo la grafica esta vez sin datos anomalos 
datosNoAnomalosPL<-pivot_longer(datosNoAnomalosHR12,cols=HR1:HR2,names_to = "variable",values_to="valor")

#Creamos el grafico:
ggplot(datosNoAnomalosPL, aes(x = tiempo, y =valor, color =variable))+geom_line(size=0.8)+labs(x="Tiempo",y="Valor")

#Miramos si correlacion a aumentado
cor(datosNoAnomalosHR12$HR1,datosNoAnomalosHR12$HR2)

#Comprobamos que ahora que hemos eliminado los datos hay una muy buena  correlacion

#Aprovechando que tenemos los datos limpios vamos a calcular la media y la mediana para HR1 y HR2
mean(datosNoAnomalosHR12$HR1)
mean(datosNoAnomalosHR12$HR2)
median(datosNoAnomalosHR12$HR1)
median(datosNoAnomalosHR12$HR2)

#De nuevo podemos observar que hay mucha correlacion  puesto que la media es muy parecida y la mediana es 145 para ambas variables.


```

**Preguntas sobre la visualización de los datos y su utilidad:**

1.  **¿Por qué es necesario que analistas de datos hagan un estudio comparando diferentes casos de parto de un monitor fetal?** *Es necesario que los analistas de datos hagan un estudio comparando diferentes casos de parto de un monitor fetal para entender cómo se comportan los datos del monitor fetal en diferentes situaciones y para encontrar patrones y tendencias que puedan ser útiles para predecir y prevenir problemas de salud durante el parto. Al analizar una gran cantidad de datos de diferentes casos de parto, los analistas de datos pueden identificar patrones y tendencias que no serían visibles en un solo caso y desarrollar modelos predictivos para detectar signos tempranos de sufrimiento fetal o problemas de salud materna.*

2.  **¿Qué representa el HR1 y HR2 en la tabla de datos del monitor fetal?** *El HR1 y HR2 en la tabla de datos del monitor fetal representan dos canales diferentes de la frecuencia cardíaca fetal. La medición de la frecuencia cardíaca fetal en dos canales diferentes proporciona una mayor precisión en la detección de cambios en la frecuencia cardíaca fetal y ayuda a los profesionales de la salud a tomar decisiones más informadas sobre el cuidado y tratamiento del feto y la madre durante el parto.*

3.  **¿Cuál es el papel del equipo médico en la interpretación de los datos del monitor fetal?** *El equipo médico es responsable de interpretar los datos del monitor fetal y tomar decisiones clínicas basadas en esa información para garantizar la salud y seguridad de la madre y el feto durante el parto.*

4.  **¿Qué técnicas de análisis de datos son comúnmente utilizadas en el análisis de un monitor fetal?** *Las técnicas de análisis de datos comúnmente utilizadas en el análisis de un monitor fetal incluyen el análisis de series de tiempo, la modelización estadística y el aprendizaje automático. El análisis de series de tiempo se utiliza para analizar las variaciones en los datos del monitor fetal a lo largo del tiempo. La modelización estadística se utiliza para construir modelos que expliquen la relación entre las variables del monitor fetal. El aprendizaje automático se utiliza para identificar patrones y tendencias en los datos del monitor fetal que puedan ser difíciles de detectar mediante otros métodos.*
